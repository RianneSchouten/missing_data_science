{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values Treatment in Data Science\n",
    "\n",
    "In an application-orientated field like data science, available datasets are almost always incomplete. Whether you like it or not, missing values treatment will become part of your analysis. \n",
    "\n",
    "Even in the situation where a data scientist quickly drops incomplete records from a dataset, a missing values treatment has (unconsciously) been chosen. Was it the most appropriate method, though? Or would the analysis outcome become different when a different missing data method was applied? \n",
    "\n",
    "In this blogpost, we present an interactive plot that can be used to explore the effect of missing data methods on several evaluation error metrics of a data science regression model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data exploration\n",
    "\n",
    "Consider dataset 'Concrete Slump Test' from https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/slump/. The data consists of 7 numerical features predicting the slump of concrete in centimeters. Because the original dataset does not contain missing values, we generated the missing values with our custom function `delete_data()` (all our functions and simulation code can be found on https://github.com/RianneSchouten/missing_data_science).\n",
    "\n",
    "Let's quickly explore the incomplete Concrete Slump Test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_slump = pd.read_table('Simulations/Data/slump_test_incomplete.txt', sep='\\t')\n",
    "data_slump.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Slag</th>\n",
       "      <th>Fly ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>SP</th>\n",
       "      <th>Coarse Aggr.</th>\n",
       "      <th>Fine Aggr.</th>\n",
       "      <th>SLUMP(cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>103.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>234.155128</td>\n",
       "      <td>77.011538</td>\n",
       "      <td>144.641026</td>\n",
       "      <td>196.002564</td>\n",
       "      <td>8.575641</td>\n",
       "      <td>878.641026</td>\n",
       "      <td>745.105128</td>\n",
       "      <td>18.048544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>79.702410</td>\n",
       "      <td>59.758251</td>\n",
       "      <td>87.252087</td>\n",
       "      <td>19.885249</td>\n",
       "      <td>2.862121</td>\n",
       "      <td>84.127386</td>\n",
       "      <td>65.604795</td>\n",
       "      <td>8.750844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>137.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>708.000000</td>\n",
       "      <td>640.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>153.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>115.250000</td>\n",
       "      <td>179.225000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>819.500000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>14.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250.150000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>193.950000</td>\n",
       "      <td>7.850000</td>\n",
       "      <td>876.500000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>21.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>308.750000</td>\n",
       "      <td>125.500000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>948.425000</td>\n",
       "      <td>789.150000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>374.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1049.500000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Cement        Slag     Fly ash       Water         SP  \\\n",
       "count   78.000000   78.000000   78.000000   78.000000  78.000000   \n",
       "mean   234.155128   77.011538  144.641026  196.002564   8.575641   \n",
       "std     79.702410   59.758251   87.252087   19.885249   2.862121   \n",
       "min    137.000000    0.000000    0.000000  160.000000   4.600000   \n",
       "25%    153.250000    0.000000  115.250000  179.225000   6.000000   \n",
       "50%    250.150000   98.000000  164.000000  193.950000   7.850000   \n",
       "75%    308.750000  125.500000  227.000000  209.000000  10.000000   \n",
       "max    374.000000  180.000000  250.000000  240.000000  19.000000   \n",
       "\n",
       "       Coarse Aggr.  Fine Aggr.   SLUMP(cm)  \n",
       "count     78.000000   78.000000  103.000000  \n",
       "mean     878.641026  745.105128   18.048544  \n",
       "std       84.127386   65.604795    8.750844  \n",
       "min      708.000000  640.600000    0.000000  \n",
       "25%      819.500000  686.500000   14.500000  \n",
       "50%      876.500000  753.000000   21.500000  \n",
       "75%      948.425000  789.150000   24.000000  \n",
       "max     1049.500000  902.000000   29.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_slump.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement           True\n",
       "Slag             True\n",
       "Fly ash          True\n",
       "Water            True\n",
       "SP               True\n",
       "Coarse Aggr.     True\n",
       "Fine Aggr.       True\n",
       "SLUMP(cm)       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_slump.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement          25\n",
       "Slag            25\n",
       "Fly ash         25\n",
       "Water           25\n",
       "SP              25\n",
       "Coarse Aggr.    25\n",
       "Fine Aggr.      25\n",
       "SLUMP(cm)        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_slump.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Slag</th>\n",
       "      <th>Fly ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>SP</th>\n",
       "      <th>Coarse Aggr.</th>\n",
       "      <th>Fine Aggr.</th>\n",
       "      <th>SLUMP(cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>904.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>746.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement   Slag  Fly ash  Water    SP  Coarse Aggr.  Fine Aggr.  SLUMP(cm)\n",
       "0   273.0   82.0    105.0  210.0   9.0         904.0       680.0       23.0\n",
       "1   163.0  149.0    191.0  180.0  12.0         843.0       746.0        0.0\n",
       "2   162.0  148.0    191.0  179.0  16.0         840.0       743.0        1.0\n",
       "3   162.0    NaN    190.0  179.0  19.0         838.0       741.0        3.0\n",
       "4     NaN  112.0      NaN    NaN  10.0         923.0       658.0       20.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_slump.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An easy way to get deal with missing values is by deleting all incomplete rows (or columns). Apart from the fact that this method can result in severely biased outcomes, dropping incomplete rows from the dataset would also make you lose a lot of valuable observed information. \n",
    "\n",
    "For example, for our `data_slump`, we would lose half of our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_slump.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data mechanisms\n",
    "\n",
    "In missing data theory, we classify missing data problems into three categories: MCAR, MAR and MNAR missingness. For any dataset with missing values in a certain feature X, the missing data is: \n",
    "\n",
    "- Missing Completely At Random (MCAR) when all values have an equal probability of being missing. \n",
    "\n",
    "- Missing At Random (MAR) when the probability of being missing depends on the values of another feature or on the values of the outcome variable. For instance, records with high values for outcome variable 'SLUMP' have a higher probability of being missing on feature 'Cement' or 'Water' (for example since it is harder to measure the percentage of cement or water in those situations).\n",
    "\n",
    "- Missing Not At Random (MNAR) when the probability of being missing in feature X depends on the unobserved (missing) data. This can either be because suitable covariates for explaining missingness have not been recorded (or are otherwise unavailable) or the probability of being missing depends on the missing values itself. Extending the previous example, if the probability of measuring 'Cement' varied according to 'Cement' itself, this is missing not at random. \n",
    "\n",
    "Below, Figures 1, 2 and 3 show the effect of MCAR, MAR and MNAR missingness on the multivariate relationship between a feature X and an outcome variable Y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## add figures: Figures/MCAR.pdf, Figures/MAR.pdf, Figures/MNAR.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the observed data alone, we cannot distinguish between MAR and MNAR data. However, there are tests available to distinguish MCAR from the other two. The easiest and most commonly used test is Little's MCAR test; a chi-square test that is available in `R`-packages `BaylorEdPsych` or `MissMech`. Rianne is currently working on developing comparable functions in Python (https://github.com/RianneSchouten/pymice)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data methods\n",
    "\n",
    "There is an extensive amount of missing data methods available in several software packages. In Python, it is easy to implement a method such as `dropna()` or to use the `mean` or `median` imputation functions from sklearn's `Imputer` class. \n",
    "\n",
    "However, how do you know which missing data method is most appropriate? What are the differences between all these methods?  \n",
    "\n",
    "In our simulation, we implemented the following six missing values treatments. \n",
    "\n",
    "- Listwise deletion: Drop incomplete rows from the dataset\n",
    "- Mean imputation: imputation with the column (i.e. feature) mean\n",
    "- Median imputation: imputation with the column (i.e. feature) median\n",
    "- Random imputation: imputation with a randomly chosen observed value (per column)\n",
    "- Regression imputation: each column (i.e. feature) is regressed on the other features. We predict each incomplete value by using the observed values of the other features. When a predictive value is unobserved, we use mean imputation first\n",
    "- Stochastic regression imputation: to account for the uncertainty of the regression model, we add (or subtract) a random amount from the prediction as obtained with regression imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation setup\n",
    "\n",
    "The setup of our simulation is as follows: \n",
    "\n",
    "- For a given dataset, we generate missing values with our function `delete_data` (in file 'simulation.ipynb'). We assign missing values to all X features, but the output variable remains complete. For different simulation rounds, we create a MCAR, MAR or MNAR missingness mechanism. In case of MAR missingness, we base the missingess in the X features on the output variable.\n",
    "- We also vary the missingness percentages. We have chosen to generate missing values with 5%, 10%, 15%, up to 55%.\n",
    "- In each simulation, the incomplete dataset is split into 60% trainingset and 40% testset. We apply six kinds of missing values treatment: `dropna()`, `mean` and `median` imputation with `.Imputer`, and `random`, `regression` and `stochastic` regression imputation with three custom functions (available in file 'simulation.ipynb'). \n",
    "- We use a simple analysis model: `LinearRegression()` from `sklearn.linear_model` and evaluate with `sklearn.metrics`: `mean_squared_error`, sqrt(`mean_squared_error`), `mean_absolute_error` and `explained_variance`. \n",
    "- Every combination of missingness mechanism, missingness proportion and missing values treatment is repeated 500 times for the real datasets and 50 times for the simulated datastes. We report the average and IQR of the evaluation metrics. \n",
    "\n",
    "For now, we used two real datasets and four simulated datasets. Import and generation of these datasets can be found in files 'import_real_data.ipynb' and 'generate_data.ipynb' on https://github.com/RianneSchouten/missing_data_science. All simulation code is in file 'simulation.ipynb'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation results\n",
    "\n",
    "Explore the outcome of the simulations in our interactive plot. Select the dataset, missingness mechanism, evaluation metric, missing data method, whether you want to see the inter quartile range (IQR) and whether you want to see the percentage of missing rows or the percentage of missing cells.\n",
    "\n",
    "A discussion of some of the output is given below the figure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add interactive plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concrete Slump Test\n",
    "\n",
    "The Concrete Slump Test data has 7 numerical features that are used to predict the slump in cubic centimeters. In file 'evaluation_complete_data.ipynb', we calculated the error metrics for the original, complete dataset. These values could serve as a baseline or reference for the outcome of the simulations. The error metrics are as follows:\n",
    "\n",
    "- MSE: 62.5\n",
    "- RMSE: 7.8\n",
    "- MAE: 6.5\n",
    "- EV: 0.15\n",
    "\n",
    "Let's start with exploring the error metrics for MCAR data. It turns out that on average, after imputing the missing values, the MSE, RMSE and MAE values decrease and the EV values increase. See for instance the MSE plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MSE plot Slump test MCAR data with rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that with a MCAR mechanism, the imputation methods perform equal for low missingness percentages. When the proportion of missing rows increases, `mean` and `median` imputation give lower MSE values than the other missing data methodologies. `regression` and `stochastic` regression imputation perform quite equal, but worse than `mean` and `median` imputation. `random` imputation seems to be the worst method, resulting in large MSE, RMSE and MAE values and explained variancs below 30%.\n",
    "\n",
    "For this particular dataset, a MCAR mechanism would give the best evaluation metrics when the `drop.na()` method is used. Interestingly, if the missingness mechanism is MAR, `drop.na()` gives MSE and RMSE values comparable with most of the imputation methods. Yet, the explained variance is still the largest of the six missing data methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MSE plot Slump test MAR data with rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, with a MAR mechanism, the error metrics after using `regression` and `stochastic` regression imputation become more distinct from `mean` and `median` imputation. This effect is most clear for higher missingness percentages. Apparently, in the MAR situation, the missingness brings such an amount of bias in the prediction of outcome variable 'SLUMP', that it is wiser to use `mean` and `median` imputation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forest Fires\n",
    "\n",
    "The Forest Fires data is obtained from https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/. A linear regression model with the complete dataset gives the following evaluation error metrics:\n",
    "\n",
    "- MSE: 4160.6\n",
    "- RMSE: 50.39\n",
    "- MAE: 21.5\n",
    "- EV: -0.8\n",
    "\n",
    "The MSE outcome of the `drop.na()` method turns out to be quite unstable and much more extreme than the other missing data methods. Therefore, it is more useful to unclick the `drop.na()` method and focus on the other methodologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MSE outcome Forest firest, rows, MCAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It immediately becomes clear that in this dataset, `regression` imputation gives results comparable with `mean` and `median` imputation. `stochastic` regression imputation still performs worse. \n",
    "\n",
    "It is most likely that this outcome has to do with the correlation structure in the data. If the features of a dataset poorly correlate (or have a non-linear correlation), a mean or median estimate is comparable with a regression estimate. With increasing correlations, independent features have more power in predicting a missing value. \n",
    "\n",
    "Another result of the correlation structure in the 'Forest Fires' dataset is the uncertainty of the regression estimates of the imputation regression model. As a result, the amount of noise added to the `stochastic` regression imputations is quite large. Therefore, the results from `stochastic` imputation come close to the results of `random` imputation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be few differences between the three missingness mechanisms. The only distinction between the three mechanisms is that with MAR missingness, the differences between the missing data methods are larger with factor 2. In other words, although the order of the missing data methods is similar for MCAR, MAR and MNAR data, any difference between two missing data methods is twice as large for MAR missingness than for MCAR or MNAR data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the performance of the regression model is quite bad. On average, we wrongly predict the area of a forest fire with 21.5 hectare. In addition, only 2 to 4 percent of the variance in 'area' is explained by the model. Note as well that if you select the IQR of the simulations, the evaluation metrics greatly overlap. This shows that the differences between the missing data methods may not be that large. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## MSE outcome rows, MCAR, IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated data\n",
    "\n",
    "In addition to the real data, we generated 4 datasets with each 10.000 records with 30 normally distributed features and 15 features with a uniform distribution. We added correlation between the features, such that 2 of the 4 datasets have a poor correlation structure and the other two a rich correlation structure. A continuous output variable is sampled by making a linear equation with the features, with a random weights vector, and the addition of some noise. We generated the output variable with two levels of noise: little and much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   16.,    18.,    52.,   100.,  1268.,   510.,   112.,    38.,\n",
       "           32.,    63.]),\n",
       " array([-0.98213356, -0.7839202 , -0.58570685, -0.38749349, -0.18928014,\n",
       "         0.00893322,  0.20714658,  0.40535993,  0.60357329,  0.80178664,  1.        ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nU/8fTJ0FE//B97sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2781063f908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "df_poor = pd.read_table('Simulations/Data/custom_dataset_poor_little.txt', sep='\\t')\n",
    "plt.hist(df_poor.corr().values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 498.,  250.,  130.,  100.,  148.,  124.,   76.,   88.,  252.,  543.]),\n",
       " array([ -9.98816871e-01,  -7.98935184e-01,  -5.99053497e-01,\n",
       "         -3.99171810e-01,  -1.99290123e-01,   5.91564378e-04,\n",
       "          2.00473252e-01,   4.00354939e-01,   6.00236626e-01,\n",
       "          8.00118313e-01,   1.00000000e+00]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEUBJREFUeJzt3X+s3Xddx/HnixU2FWG/ulnajW6hIksMY7lZFkkENgJs\nGDrjpiXiCtY04DQYNFLExB/RuPmHM0QDVoYUVNgYklUYYtmPEBM26GRsjDl6N5DV1rWwH0gIk8Hb\nP87n4qE9t/fc3nPu7T48H8nJ+X4/38/5ft/3c05f93s/55xvU1VIkvr1tJUuQJI0XQa9JHXOoJek\nzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXOrVroAgFNPPbXWr1+/0mVI0lPKnXfe+bWqWr1Q\nv2Mi6NevX8/u3btXugxJekpJ8p/j9HPqRpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0\nktQ5g16SOndMfDNWklbS+m0fW7Fjf+WqV0/9GJ7RS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z\n9JLUOYNekjpn0EtS5wx6SeqcQS9JnRsr6JN8Jck9Se5Ksru1nZxkV5I97f6k1p4k70gym+TuJOdN\n8weQJB3ZYs7oX1ZV51bVTFvfBtxcVRuAm9s6wMXAhnbbCrxzUsVKkhZvKVM3G4EdbXkHcOlQ+/tq\n4HbgxCRrlnAcSdISjBv0BfxrkjuTbG1tp1fVfoB2f1prXws8NPTYva1NkrQCxr0e/Yural+S04Bd\nSf7jCH0zoq0O6zT4hbEV4MwzzxyzDEnSYo0V9FW1r90fSPIR4Hzg4SRrqmp/m5o50LrvBc4Yevg6\nYN+IfW4HtgPMzMwc9otgXL3/hwGStFQLTt0k+bEkPz63DLwC+AKwE9jcum0GbmzLO4Er2qdvLgAe\nn5vikSQtv3HO6E8HPpJkrv8/VtW/JPkscH2SLcBXgctb/5uAS4BZ4FvAGyZetSRpbAsGfVU9CLxw\nRPvXgYtGtBdw5USqkyQtmd+MlaTOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJek\nzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6Seqc\nQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0bO+iTHJfkc0k+2tbPSnJH\nkj1JrkvyjNZ+fFufbdvXT6d0SdI4FnNG/2bgvqH1q4FrqmoD8CiwpbVvAR6tqucB17R+kqQVMlbQ\nJ1kHvBp4d1sPcCFwQ+uyA7i0LW9s67TtF7X+kqQVMO4Z/V8Cvwt8r62fAjxWVU+29b3A2ra8FngI\noG1/vPX/AUm2JtmdZPfBgwePsnxJ0kIWDPokPwccqKo7h5tHdK0xtv1/Q9X2qpqpqpnVq1ePVawk\nafFWjdHnxcBrklwCnAA8i8EZ/olJVrWz9nXAvtZ/L3AGsDfJKuDZwCMTr1ySNJYFz+ir6m1Vta6q\n1gObgFuq6peBW4HLWrfNwI1teWdbp22/paoOO6OXJC2PpXyO/q3AW5LMMpiDv7a1Xwuc0trfAmxb\nWomSpKUYZ+rm+6rqNuC2tvwgcP6IPt8GLp9AbZKkCfCbsZLUOYNekjpn0EtS5wx6SeqcQS9JnTPo\nJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16S\nOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnVsw6JOc\nkOQzST6f5N4kf9Taz0pyR5I9Sa5L8ozWfnxbn23b10/3R5AkHck4Z/RPABdW1QuBc4FXJbkAuBq4\npqo2AI8CW1r/LcCjVfU84JrWT5K0QhYM+hr4Zlt9ersVcCFwQ2vfAVzalje2ddr2i5JkYhVLkhZl\nrDn6JMcluQs4AOwCHgAeq6onW5e9wNq2vBZ4CKBtfxw4ZcQ+tybZnWT3wYMHl/ZTSJLmNVbQV9V3\nq+pcYB1wPvCCUd3a/aiz9zqsoWp7Vc1U1czq1avHrVeStEiL+tRNVT0G3AZcAJyYZFXbtA7Y15b3\nAmcAtO3PBh6ZRLGSpMUb51M3q5Oc2JZ/BHg5cB9wK3BZ67YZuLEt72zrtO23VNVhZ/SSpOWxauEu\nrAF2JDmOwS+G66vqo0m+CHwwyZ8AnwOubf2vBd6fZJbBmfymKdQtSRrTgkFfVXcDLxrR/iCD+fpD\n278NXD6R6iRJS+Y3YyWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1\nzqCXpM4Z9JLUOYNekjo3zmWKNY/12z62Isf9ylWvXpHjStO2Uv+meucZvSR1zqCXpM4Z9JLUOYNe\nkjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ1bMOiT\nnJHk1iT3Jbk3yZtb+8lJdiXZ0+5Pau1J8o4ks0nuTnLetH8ISdL8xjmjfxL47ap6AXABcGWSc4Bt\nwM1VtQG4ua0DXAxsaLetwDsnXrUkaWwLBn1V7a+qf2/L/wPcB6wFNgI7WrcdwKVteSPwvhq4HTgx\nyZqJVy5JGsui5uiTrAdeBNwBnF5V+2HwywA4rXVbCzw09LC9rU2StALGDvokzwQ+DPxWVX3jSF1H\ntNWI/W1NsjvJ7oMHD45bhiRpkcYK+iRPZxDy/1BV/9SaH56bkmn3B1r7XuCMoYevA/Ydus+q2l5V\nM1U1s3r16qOtX5K0gHE+dRPgWuC+qvqLoU07gc1teTNw41D7Fe3TNxcAj89N8UiSlt+qMfq8GPgV\n4J4kd7W23wOuAq5PsgX4KnB523YTcAkwC3wLeMNEK5YkLcqCQV9V/8boeXeAi0b0L+DKJdYlSZoQ\nvxkrSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z\n9JLUOYNekjo3zvXopRW3ftvHVuS4X7nq1StyXGmSPKOXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9J\nnfPjlU9BK/VRQ/DjhtJTkWf0ktQ5g16SOufUjXQETpOpB57RS1LnDHpJ6pxBL0mdM+glqXMLBn2S\n9yQ5kOQLQ20nJ9mVZE+7P6m1J8k7kswmuTvJedMsXpK0sHHO6N8LvOqQtm3AzVW1Abi5rQNcDGxo\nt63AOydTpiTpaC0Y9FX1KeCRQ5o3Ajva8g7g0qH299XA7cCJSdZMqlhJ0uId7Rz96VW1H6Ddn9ba\n1wIPDfXb29okSStk0l+Yyoi2Gtkx2cpgeoczzzxzwmVoWlbyC0SSjs7RntE/PDcl0+4PtPa9wBlD\n/dYB+0btoKq2V9VMVc2sXr36KMuQJC3kaIN+J7C5LW8Gbhxqv6J9+uYC4PG5KR5J0spYcOomyQeA\nlwKnJtkL/AFwFXB9ki3AV4HLW/ebgEuAWeBbwBumULMkaREWDPqqeu08my4a0beAK5dalKSV4/sw\n/fGbsZLUOYNekjpn0EtS5wx6Seqc/8OUdIzyTVFNimf0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+gl\nqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6\nZ9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzk0l6JO8Ksn9SWaTbJvGMSRJ45l40Cc5Dvhr4GLg\nHOC1Sc6Z9HEkSeOZxhn9+cBsVT1YVf8LfBDYOIXjSJLGMI2gXws8NLS+t7VJklbAqinsMyPa6rBO\nyVZga1v9ZpL7j/J4pwJfO8rHTpN1LY51Lc6xWhccu7Udk3Xl6iXV9dxxOk0j6PcCZwytrwP2Hdqp\nqrYD25d6sCS7q2pmqfuZNOtaHOtanGO1Ljh2a/thrmsaUzefBTYkOSvJM4BNwM4pHEeSNIaJn9FX\n1ZNJfgP4BHAc8J6qunfSx5EkjWcaUzdU1U3ATdPY9whLnv6ZEutaHOtanGO1Ljh2a/uhrStVh71P\nKknqiJdAkKTOPSWCPsnlSe5N8r0k8747Pd+lF9obw3ck2ZPkuvYm8STqOjnJrrbfXUlOGtHnZUnu\nGrp9O8mlbdt7k3x5aNu5y1VX6/fdoWPvHGpfyfE6N8mn2/N9d5JfGto20fFa6FIdSY5vP/9sG4/1\nQ9ve1trvT/LKpdRxFHW9JckX2/jcnOS5Q9tGPqfLVNfrkxwcOv6vDW3b3J73PUk2L3Nd1wzV9KUk\njw1tm+Z4vSfJgSRfmGd7kryj1X13kvOGtk12vKrqmL8BLwCeD9wGzMzT5zjgAeBs4BnA54Fz2rbr\ngU1t+V3AmyZU158D29ryNuDqBfqfDDwC/Ghbfy9w2RTGa6y6gG/O075i4wX8JLChLT8H2A+cOOnx\nOtLrZajPrwPvasubgOva8jmt//HAWW0/xy1jXS8beg29aa6uIz2ny1TX64G/GvHYk4EH2/1Jbfmk\n5arrkP6/yeADIlMdr7bvnwXOA74wz/ZLgI8z+O7RBcAd0xqvp8QZfVXdV1ULfaFq5KUXkgS4ELih\n9dsBXDqh0ja2/Y2738uAj1fVtyZ0/Pkstq7vW+nxqqovVdWetrwPOACsntDxh41zqY7hem8ALmrj\nsxH4YFU9UVVfBmbb/palrqq6deg1dDuD76pM21IubfJKYFdVPVJVjwK7gFetUF2vBT4woWMfUVV9\nisGJ3Xw2Au+rgduBE5OsYQrj9ZQI+jHNd+mFU4DHqurJQ9on4fSq2g/Q7k9boP8mDn+R/Wn7s+2a\nJMcvc10nJNmd5Pa56SSOofFKcj6Ds7QHhponNV7jXKrj+33aeDzOYHymeZmPxe57C4OzwjmjntPl\nrOsX2vNzQ5K5L04eE+PVprjOAm4Zap7WeI1jvtonPl5T+Xjl0UjySeAnRmx6e1XdOM4uRrTVEdqX\nXNe4+2j7WQP8NIPvF8x5G/DfDMJsO/BW4I+Xsa4zq2pfkrOBW5LcA3xjRL+VGq/3A5ur6nut+ajH\na9QhRrQd+nNO5TW1gLH3neR1wAzwkqHmw57Tqnpg1OOnUNc/Ax+oqieSvJHBX0MXjvnYadY1ZxNw\nQ1V9d6htWuM1jmV7fR0zQV9VL1/iLua79MLXGPxJtKqdlY28JMPR1JXk4SRrqmp/C6YDR9jVLwIf\nqarvDO17f1t8IsnfAb+znHW1qRGq6sEktwEvAj7MCo9XkmcBHwN+v/1JO7fvox6vEca5VMdcn71J\nVgHPZvCn+FiX+ZhiXSR5OYNfni+pqifm2ud5TicRXAvWVVVfH1r9W+Dqoce+9JDH3jaBmsaqa8gm\n4MrhhimO1zjmq33i49XT1M3ISy/U4N2NWxnMjwNsBsb5C2EcO9v+xtnvYXODLezm5sUvBUa+Oz+N\nupKcNDf1keRU4MXAF1d6vNpz9xEGc5cfOmTbJMdrnEt1DNd7GXBLG5+dwKYMPpVzFrAB+MwSallU\nXUleBPwN8JqqOjDUPvI5Xca61gytvga4ry1/AnhFq+8k4BX84F+2U62r1fZ8Bm9sfnqobZrjNY6d\nwBXt0zcXAI+3k5nJj9e03nGe5A34eQa/5Z4AHgY+0dqfA9w01O8S4EsMfiO/faj9bAb/EGeBDwHH\nT6iuU4CbgT3t/uTWPgO8e6jfeuC/gKcd8vhbgHsYBNbfA89crrqAn2nH/ny733IsjBfwOuA7wF1D\nt3OnMV6jXi8MpoJe05ZPaD//bBuPs4ce+/b2uPuBiyf8el+ork+2fwdz47Nzoed0mer6M+Dedvxb\ngZ8aeuyvtnGcBd6wnHW19T8ErjrkcdMerw8w+NTYdxjk1xbgjcAb2/Yw+E+aHmjHnxl67ETHy2/G\nSlLnepq6kSSNYNBLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktS5/wO6ezaoFN6xNQAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2781137f0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_rich = pd.read_table('Simulations/Data/custom_dataset_rich_little.txt', sep = '\\t')\n",
    "plt.hist(df_rich.corr().values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below shows the evaluation metrics for the complete datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# table with output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the values, it becomes clear that the simulated datasets are quite perfect datasets. All four datasets have an explained variance perfecentage of 99.99%. The MSE is 0.01 for the datasets with little noise and 24.6 for the data with much noise. The MAE increases from 0.08 to 4.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perfect characteristics of these datasets make that some missing data methods give exactly similar results. For instance, `mean` and `median` imputation give the same results, and `regression` and `stochastic` imputation as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data poor correlation and much noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can understand from the simulated datasets, is that the performance of `regression` imputation is clearly affected by the correlation structure of the data. Earlier, we saw that `regression` imputation performs comparable with `mean` and `median` imputation when the correlation structure is poor. For the simulated datasets with the poor correlation structure, `regression` imputation gives even lower MSE, RMSE and MAE values than `mean` and `median` imputation. It seems that `regression` imputation is a useful method when the correlation structure of the data is poor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The effect of missing values treatment on the outcome of a data science regression model depends on the characteristics of the data. Yet, this effect may be smaller than we think. Some general conclusions:\n",
    "\n",
    "1. For relatively low missingness percentages, there is almost no difference between the missing data methodologies. The differences occur for higher missingness percentages. \n",
    "2. When the missingness in the trainingset is similar to the missingness in the testset (as is the case in our simulations), the type of missingness mechanism is not on influence on the performance of the model or the choice of missing data method.\n",
    "3. The performance of `regression` imputation is sensitive for the correlation structure in the data. With small correlations, the evaluations metrics after using `regression` imputation are smaller than when using `mean` or `median` imputation.\n",
    "4. `mean` and `median` imputation seem to give the most stable results, independent of specific data characteristics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact information\n",
    "\n",
    "Rianne Schouten, Missing Data Specialist, rianne.schouten@dpa.nl\n",
    "\n",
    "Coen Seinen, Data Scientist, coen.seinen@bigdatarepublic.nl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
