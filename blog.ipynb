{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values Treatment in Data Science\n",
    "\n",
    "In an application-orientated field like data science, available datasets are almost always incomplete. Whether you like it or not, missing values treatment will therefore become part of the whole process of data exploration, data cleaning, feature engineering and the development of an analysis model. \n",
    "\n",
    "Even in the situation where a data scientist quickly drops incomplete records from a dataset, a missing values treatment has (unconsciously) been chosen. Was it the most appropriate method, though? Or would the analysis outcome become different when a different missing data method was applied? \n",
    "\n",
    "In this post, we present an interactive plot that can be used to explore the effect of missing data methods on evaluation error metrics of a data science regression model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data exploration\n",
    "\n",
    "Consider dataset 'Concrete Slump Test' from https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/slump/. The data consists of 7 numerical features predicting the slump of concrete in centimeters. Because the original dataset does not contain missing values, we generated the missing values with our custom function `delete_data()` (all our functions and simulation code can be found on https://github.com/RianneSchouten/missing_data_science).\n",
    "\n",
    "Let's quickly explore the incomplete dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_slump = pd.read_table('Data/slump_test_MCAR.txt', sep='\\t')\n",
    "data_slump.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Slag</th>\n",
       "      <th>Fly ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>SP</th>\n",
       "      <th>Coarse Aggr.</th>\n",
       "      <th>Fine Aggr.</th>\n",
       "      <th>SLUMP(cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1.030000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.006036</td>\n",
       "      <td>-0.104102</td>\n",
       "      <td>-0.124301</td>\n",
       "      <td>-0.018298</td>\n",
       "      <td>-0.012871</td>\n",
       "      <td>0.024598</td>\n",
       "      <td>0.054493</td>\n",
       "      <td>-2.004869e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.010530</td>\n",
       "      <td>1.012177</td>\n",
       "      <td>1.028261</td>\n",
       "      <td>1.006384</td>\n",
       "      <td>1.050937</td>\n",
       "      <td>0.990258</td>\n",
       "      <td>1.061685</td>\n",
       "      <td>1.004890e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.183465</td>\n",
       "      <td>-1.295953</td>\n",
       "      <td>-1.753063</td>\n",
       "      <td>-1.848249</td>\n",
       "      <td>-1.481747</td>\n",
       "      <td>-2.000638</td>\n",
       "      <td>-1.570661</td>\n",
       "      <td>-2.072577e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.992366</td>\n",
       "      <td>-1.295953</td>\n",
       "      <td>-0.561920</td>\n",
       "      <td>-0.853710</td>\n",
       "      <td>-0.909064</td>\n",
       "      <td>-0.707455</td>\n",
       "      <td>-0.878176</td>\n",
       "      <td>-4.074917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.232578</td>\n",
       "      <td>0.206528</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>-0.157533</td>\n",
       "      <td>-0.246900</td>\n",
       "      <td>-0.022494</td>\n",
       "      <td>0.093523</td>\n",
       "      <td>3.963428e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.943466</td>\n",
       "      <td>0.632010</td>\n",
       "      <td>0.844805</td>\n",
       "      <td>0.582155</td>\n",
       "      <td>0.522643</td>\n",
       "      <td>0.787237</td>\n",
       "      <td>0.796320</td>\n",
       "      <td>6.834265e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.835897</td>\n",
       "      <td>1.662472</td>\n",
       "      <td>1.164501</td>\n",
       "      <td>2.129907</td>\n",
       "      <td>3.743983</td>\n",
       "      <td>1.886300</td>\n",
       "      <td>2.576315</td>\n",
       "      <td>1.257594e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Cement       Slag    Fly ash      Water         SP  Coarse Aggr.  \\\n",
       "count  78.000000  78.000000  78.000000  78.000000  78.000000     78.000000   \n",
       "mean    0.006036  -0.104102  -0.124301  -0.018298  -0.012871      0.024598   \n",
       "std     1.010530   1.012177   1.028261   1.006384   1.050937      0.990258   \n",
       "min    -1.183465  -1.295953  -1.753063  -1.848249  -1.481747     -2.000638   \n",
       "25%    -0.992366  -1.295953  -0.561920  -0.853710  -0.909064     -0.707455   \n",
       "50%     0.232578   0.206528  -0.000171  -0.157533  -0.246900     -0.022494   \n",
       "75%     0.943466   0.632010   0.844805   0.582155   0.522643      0.787237   \n",
       "max     1.835897   1.662472   1.164501   2.129907   3.743983      1.886300   \n",
       "\n",
       "       Fine Aggr.     SLUMP(cm)  \n",
       "count   78.000000  1.030000e+02  \n",
       "mean     0.054493 -2.004869e-16  \n",
       "std      1.061685  1.004890e+00  \n",
       "min     -1.570661 -2.072577e+00  \n",
       "25%     -0.878176 -4.074917e-01  \n",
       "50%      0.093523  3.963428e-01  \n",
       "75%      0.796320  6.834265e-01  \n",
       "max      2.576315  1.257594e+00  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_slump.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement           True\n",
       "Slag             True\n",
       "Fly ash          True\n",
       "Water            True\n",
       "SP               True\n",
       "Coarse Aggr.     True\n",
       "Fine Aggr.       True\n",
       "SLUMP(cm)       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_slump.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement          25\n",
       "Slag            25\n",
       "Fly ash         25\n",
       "Water           25\n",
       "SP              25\n",
       "Coarse Aggr.    25\n",
       "Fine Aggr.      25\n",
       "SLUMP(cm)        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_slump.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Slag</th>\n",
       "      <th>Fly ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>SP</th>\n",
       "      <th>Coarse Aggr.</th>\n",
       "      <th>Fine Aggr.</th>\n",
       "      <th>SLUMP(cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.517804</td>\n",
       "      <td>0.638098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.945600</td>\n",
       "      <td>0.568593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.852227</td>\n",
       "      <td>1.180482</td>\n",
       "      <td>0.493932</td>\n",
       "      <td>-0.853710</td>\n",
       "      <td>1.238496</td>\n",
       "      <td>-0.465871</td>\n",
       "      <td>0.101456</td>\n",
       "      <td>-2.072577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.864967</td>\n",
       "      <td>1.163861</td>\n",
       "      <td>0.493932</td>\n",
       "      <td>-0.903437</td>\n",
       "      <td>2.670203</td>\n",
       "      <td>-0.499977</td>\n",
       "      <td>0.053862</td>\n",
       "      <td>-1.957744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.864967</td>\n",
       "      <td>1.163861</td>\n",
       "      <td>0.482168</td>\n",
       "      <td>-0.903437</td>\n",
       "      <td>3.743983</td>\n",
       "      <td>-0.522715</td>\n",
       "      <td>0.022133</td>\n",
       "      <td>-1.728077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.966886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.135368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.443620</td>\n",
       "      <td>-1.294619</td>\n",
       "      <td>0.224093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement      Slag   Fly ash     Water        SP  Coarse Aggr.  Fine Aggr.  \\\n",
       "0       NaN       NaN -0.517804  0.638098       NaN           NaN   -0.945600   \n",
       "1 -0.852227  1.180482  0.493932 -0.853710  1.238496     -0.465871    0.101456   \n",
       "2 -0.864967  1.163861  0.493932 -0.903437  2.670203     -0.499977    0.053862   \n",
       "3 -0.864967  1.163861  0.482168 -0.903437  3.743983     -0.522715    0.022133   \n",
       "4 -0.966886       NaN       NaN  1.135368       NaN      0.443620   -1.294619   \n",
       "\n",
       "   SLUMP(cm)  \n",
       "0   0.568593  \n",
       "1  -2.072577  \n",
       "2  -1.957744  \n",
       "3  -1.728077  \n",
       "4   0.224093  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_slump.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An easy way to get rid of missing values is by deleting all incomplete rows. Apart from the fact that this method can result in severely biased outcomes, dropping incomplete rows from the dataset would also make you lose a lot of valuable observed information. \n",
    "\n",
    "For example, for our `data_slump`, we would lose half of our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_slump.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data mechanisms\n",
    "\n",
    "In missing data theory, we classify missing values into three kind of problems: MCAR, MAR and MNAR. For any dataset with missing values in a certain feature X, the missing data is: \n",
    "\n",
    "- Missing Completely At Random (MCAR) when all values have an equal probability of being missing. \n",
    "\n",
    "- Missing At Random (MAR) when the probability of being missing depends on the values of another feature or the outcome variable. For instance, records with high values for outcome variable 'SLUMP' have a higher probability of being missing on feature 'Cement' or 'Water' (maybe because in those cases it is harder to measure these features).\n",
    "\n",
    "- Missing Not At Random (MNAR) when the probability of being missing in feature X depends on the unobserved (missing) data. This can either be because suitable covariates for explaining missingness have not been recorded (or are otherwise unavailable) or the probability of being missing depends on the missing values itself. Extending the previous example, if the probability of measuring 'Cement' varied according to 'Cement' itself, this is missing not at random. \n",
    "\n",
    "Below, Figures 1, 2 and 3 show the effect of MCAR, MAR and MNAR missingness on the multivariate relationship between feature X and outcome variable Y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## add figures: Figures/MCAR.pdf, Figures/MAR.pdf, Figures/MNAR.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the observed data alone, we cannot distinguish between MAR and MNAR data. However, there are tests available to distinguish MCAR from the other two. The easiest test is Little's MCAR test (add reference). This test uses a chi-square test to know whether the overall missingness is MCAR. The null hypothesis is defined as: the data is MCAR. When the test returns a p-value smaller than 0.05, the null hypothesis can be rejected.\n",
    "\n",
    "A basic Little's MCAR test can be extracted from Rianne's github. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import RianneSchouten/pymice/exploration/mcar_tests') Hoe doe ik dat? \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as ma\n",
    "import scipy.stats as st\n",
    "\n",
    "def checks_input_mcar_tests(data):\n",
    "    \"\"\" Checks whether the input parameter of class McarTests is correct\n",
    "            Parameters\n",
    "            ----------\n",
    "            data:\n",
    "                The input of McarTests specified as 'data'\n",
    "            Returns\n",
    "            -------\n",
    "            bool\n",
    "                True if input is correct\n",
    "            \"\"\"\n",
    "\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        print(\"Error: Data should be a Pandas DataFrame\")\n",
    "        return False\n",
    "\n",
    "    if not any(data.dtypes.values == np.float):\n",
    "        if not any(data.dtypes.values == np.int):\n",
    "            print(\"Error: Dataset cannot contain other value types than floats and/or integers\")\n",
    "            return False\n",
    "\n",
    "    if not data.isnull().values.any():\n",
    "        print(\"Error: No NaN's in given data\")\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "class McarTests():\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def mcar_test(self):\n",
    "        \"\"\" Implementation of Little's MCAR test\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: Pandas DataFrame\n",
    "            An incomplete dataset with samples as index and variables as columns\n",
    "        Returns\n",
    "        -------\n",
    "        p_value: Float\n",
    "            This value is the outcome of a chi-square statistical test, testing whether the null hypothesis\n",
    "            'the missingness mechanism of the incomplete dataset is MCAR' can be rejected.\n",
    "        \"\"\"\n",
    "\n",
    "        if not checks_input_mcar_tests(self.data):\n",
    "            raise Exception(\"Input not correct\")\n",
    "\n",
    "        dataset = self.data.copy()\n",
    "        vars = dataset.dtypes.index.values\n",
    "        n_var = dataset.shape[1]\n",
    "\n",
    "        # mean and covariance estimates\n",
    "        # ideally, this is done with a maximum likelihood estimator\n",
    "        gmean = dataset.mean()\n",
    "        gcov = dataset.cov()\n",
    "\n",
    "        # set up missing data patterns\n",
    "        r = 1 * dataset.isnull()\n",
    "        mdp = np.dot(r, list(map(lambda x: ma.pow(2, x), range(n_var))))\n",
    "        sorted_mdp = sorted(np.unique(mdp))\n",
    "        n_pat = len(sorted_mdp)\n",
    "        correct_mdp = list(map(lambda x: sorted_mdp.index(x), mdp))\n",
    "        dataset['mdp'] = pd.Series(correct_mdp, index=dataset.index)\n",
    "\n",
    "        # calculate statistic and df\n",
    "        pj = 0\n",
    "        d2 = 0\n",
    "        for i in range(n_pat):\n",
    "            dataset_temp = dataset.loc[dataset['mdp'] == i, vars]\n",
    "            select_vars = ~dataset_temp.isnull().any()\n",
    "            pj += np.sum(select_vars)\n",
    "            select_vars = vars[select_vars]\n",
    "            means = dataset_temp[select_vars].mean() - gmean[select_vars]\n",
    "            select_cov = gcov.loc[select_vars, select_vars]\n",
    "            mj = len(dataset_temp)\n",
    "            parta = np.dot(means.T, np.linalg.solve(select_cov, np.identity(select_cov.shape[1])))\n",
    "            d2 += mj * (np.dot(parta, means))\n",
    "\n",
    "        df = pj - n_var\n",
    "\n",
    "        # perform test and save output\n",
    "        p_value = 1- st.chi2.cdf(d2, df)\n",
    "        rejected = p_value > 0.05\n",
    "\n",
    "        return \"Outcome MCAR-test: p-value = {}, therefore null hypothesis that data is MCAR is {}\"\\\n",
    "    .format(p_value, rejected)\n",
    "\n",
    "    def mcar_t_tests(self):\n",
    "        \"\"\" MCAR tests for each pair of variables\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: Pandas DataFrame\n",
    "            An incomplete dataset with samples as index and variables as columns\n",
    "        Returns\n",
    "        -------\n",
    "        mcar_matrix: Pandas DataFrame\n",
    "            A square Pandas DataFrame containing True/False for each pair of variables\n",
    "            True: Missingness in index variable is MCAR for column variable\n",
    "            False: Missingness in index variable is not MCAR for column variable\n",
    "        \"\"\"\n",
    "\n",
    "        if not checks_input_mcar_tests(self.data):\n",
    "            raise Exception(\"Input not correct\")\n",
    "\n",
    "        dataset = self.data.copy()\n",
    "        vars = dataset.dtypes.index.values\n",
    "        mcar_matrix = pd.DataFrame(data=np.zeros(shape=(dataset.shape[1], dataset.shape[1])),\n",
    "                                   columns=vars, index=vars)\n",
    "\n",
    "        for var in vars:\n",
    "            for tvar in vars:\n",
    "                part_one = dataset.loc[dataset[var].isnull(), tvar].dropna()\n",
    "                part_two = dataset.loc[~dataset[var].isnull(), tvar].dropna()\n",
    "                mcar_matrix.loc[var, tvar] = st.ttest_ind(part_one, part_two, equal_var=False).pvalue\n",
    "\n",
    "        mcar_matrix = mcar_matrix[mcar_matrix.notnull()] > 0.05\n",
    "\n",
    "        return mcar_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Outcome MCAR-test: p-value = 0.008995931317370864, therefore null hypothesis that data is MCAR is False'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "McarTests(data_slump).mcar_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Outcome MCAR-test: p-value = 0.8486283516447674, therefore null hypothesis that data is MCAR is True'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_slump_MAR = pd.read_table('Data/slump_test_MAR.txt', sep='\\t')\n",
    "McarTests(data_slump_MAR).mcar_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to check whether data is MCAR or not, can be done with `mcar_t_tests`: independent samples t-tests which test whether for a given feature, the observed values of another feature are different from the unobserved values. An important assumption of a t-test is normality, and this test is therefore only reliable for normally distributed features. Function `mcar_t_tests` returns `True` if a row feature is MCAR for the column feature.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Slag</th>\n",
       "      <th>Fly ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>SP</th>\n",
       "      <th>Coarse Aggr.</th>\n",
       "      <th>Fine Aggr.</th>\n",
       "      <th>SLUMP(cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cement</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slag</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fly ash</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coarse Aggr.</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fine Aggr.</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLUMP(cm)</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Cement   Slag  Fly ash  Water     SP  Coarse Aggr.  Fine Aggr.  \\\n",
       "Cement         False   True     True   True   True          True        True   \n",
       "Slag           False  False     True   True   True          True        True   \n",
       "Fly ash         True   True    False   True   True          True        True   \n",
       "Water           True   True     True  False   True          True        True   \n",
       "SP              True   True     True   True  False          True        True   \n",
       "Coarse Aggr.    True   True     True   True   True         False        True   \n",
       "Fine Aggr.      True   True     True   True   True          True       False   \n",
       "SLUMP(cm)      False  False    False  False  False         False       False   \n",
       "\n",
       "              SLUMP(cm)  \n",
       "Cement             True  \n",
       "Slag               True  \n",
       "Fly ash            True  \n",
       "Water              True  \n",
       "SP                 True  \n",
       "Coarse Aggr.       True  \n",
       "Fine Aggr.         True  \n",
       "SLUMP(cm)         False  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "McarTests(data_slump).mcar_t_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data methods\n",
    "\n",
    "Because of the large collection of possible methods for dealing with missing data, it can be hard to choose a method for your situation. It is easy to implement a method such as `dropna()` or use the `mean` or `median` imputation functions from `.Imputer` from Scikit-learn. But which of those methods is best? \n",
    "\n",
    "In our simulation, we implemented the following imputation methods: \n",
    "\n",
    "- Mean imputation: imputation with the column (feature) mean\n",
    "- Median imputation: imputation with the column (feature) median\n",
    "- Random imputation: we randomly choose an unobserved value from the column (feature)\n",
    "- Regression imputation: each column (feature) is regressed on the other features. Each incomplete value is predicted with the observed values of the other features. When a predictive value is unobserved as well, we first impute this value with the column (feature) mean\n",
    "- Stochastic regression imputation: to account for the uncertainty of the regression model, we add (or subtract) a random amount from the prediction as obtained with regression imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation setup\n",
    "\n",
    "We performed an extensive simulation study to test the effect of the missing data methods on the outcome of a regression model. Our setup is as follows:\n",
    "\n",
    "- We obtained two complete, real datasets and created 6 simulated datasets.\n",
    "- For each dataset, we generate several percentages of missing values according to the three missingness mechanisms. For this, we created function `delete_data` (in file simulation.ipynb). We assign missing values to all X features, but not to the output variable Y. For MAR missingness, we base the missingess in the X features on the output variable Y.\n",
    "- In each simulation, the incomplete dataset is split into 60% trainingset and 40% testset. We apply six kinds of missing values treatment: `dropna()`, `mean` and `median` imputation with `.Imputer`, and `random`, `regression` and `stochastic` regression imputation with three custom functions (avaialable in file simulation.ipynb). As our analysis model, we use a simple regression model `LinearRegression()` from `sklearn.linear_model` and evaluate with `sklearn.metrics`: `mean_squared_error` and `explained_variance`. \n",
    "- We repeat the second and third step 500 times for the real datasets and 50 times for the six custom datasets. We report the average and IQR of the evaluation metrics. All simulation code can be found in file simulation.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation results\n",
    "\n",
    "Check the outcome in our interactive plot. Select the dataset, missingness mechanism, evaluation metric, missing data method, whether you want to see the inter quartile range (IQR) and whether you want the percentage of missing rows or the percentage of missing cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concrete slump test\n",
    "\n",
    "A linear regression model with the original, complete dataset gives the following evaluation error metrics:\n",
    "\n",
    "- MAE: 6.5\n",
    "- MSE: 62.5\n",
    "- R2: 0.09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared with the complete dataset, the average evaluation error metrics after dealing with the missing values are a bit lower for MSE (around 50), comparable for MAE (around 7) and quite higher for R2 (around 0.3). \n",
    "\n",
    "For the concrete slump test dataset, a MCAR mechanism would give the lowest MSE, RMSE and MAE value when the `drop.na()` method is used. This performance most probably occurs because of the huge decreases in data records. `random` imputation seems to be the worst method, resulting in explained variance values under 30%.\n",
    "\n",
    "To distinguish between the four imputation models, we have to zoom the figure. It turns out that for higher missingness percentages, `mean` imputation returns lower MSE values than `median` values. `regression` gives higher values, and `stochastic` regression imputation even higher. Note that the differences between the methods are small, and even though we performed 500 simulations, the IQR of our simulation overlap for all missingness percentages. \n",
    "\n",
    "Interestingly, if the missingness mechanism is MAR, `drop.na()` gives MSE and RMSE values comparable with most of the imputation methods. Yet, the explained variance is still the largest of the six missing data methods. For MAR mechanisms, `regression` and `stochastic` imputation become more distinct from `mean` and `median` imputation. This effect is most clear for higher missingness percentages. Apparently, in the MAR situation, the missingness brings such an amount of bias in the prediction of outcome variable 'SLUMP', that it is wiser to use `mean` and `median` imputation. \n",
    "\n",
    "With MNAR missingness, the situation becomes comparable with the MCAR missingness. Because in both MCAR and MNAR, the missingness does not depend on the outcome variable 'SLUMP', the performance of the analysis model is not much influenced by the different types of missingness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2 example figures van de plot hier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forest fires\n",
    "\n",
    "The forest fires data is obtained from https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/. A linear regression model with the complete dataset gives the following evaluation error metrics:\n",
    "\n",
    "- MAE: 21.5\n",
    "- MSE: 4160.6\n",
    "- R2: -1.88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE outcome of the `drop.na()` method turns out to be quite unstable. The same applies to the other metrics. In addition, `drop.na()` gives extremer values than the other missing data methods. Therefore, it is more useful to unclick the `drop.na()` method and focus on the other methodologies.\n",
    "\n",
    "It becomes immediately clear that in contrast with the 'Concrete Slump Test' dataset, `regression` imputation now gives results comparable with `mean` and `median` imputation instead of `stochastic` imputation. It is most likely that this has to do with the correlation structure in the data. If the features of a dataset poorly correlate, a mean or median estimate is comparable with a regression estimate. With increasing correlations, independent features have more power in predicting a missing value. Another result of the poor correlation structure in the 'Forest Fires' dataset is the uncertainty of the regression estimates of the imputation regression model. As a result, the amount of noise added to the `stochastic` regression imputed values is quite large and therefore, the results from `stochastic` imputation come close to the results of `random` imputation. \n",
    "\n",
    "There seem to be few differences between the three missingness mechanisms. The only distinction between the three mechanisms is that with MAR missingness, the differences between the missing data methods are larger with factor 2. In other words, although the order of the missing data methods is similar for MCAR, MAR and MNAR data, any difference between two missing data methods is twice as large for MAR missingness than for MCAR or MNAR data.  \n",
    "\n",
    "Note as well that the performance of the Forest Fires model is quite bad. On average we wrongly predict the area of a forest fire with 21.5 hectare. In addition, only 2 to 4 percent of the variance in 'area' is explained by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## two plots here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated datasets\n",
    "\n",
    "Our simulation code is available in file generate_data.ipynb. In short, we generated 6 datasets with each 10.000 records with 25 normally distributed features and 20 features with a uniform distribution. We added correlation between the features, such that 3 of the 6 datasets have a poor correlation structure and the other three a rich correlation structure. A continuous output variable is sampled by making a linear equation with the features, with a random weights vector, and the addition of some noise. We generated the output variable with three levels of noise: small, medium and large. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   44.,    38.,    74.,   140.,  1020.,   584.,   146.,    66.,\n",
       "           18.,    79.]),\n",
       " array([-0.98828885, -0.78945996, -0.59063108, -0.39180219, -0.19297331,\n",
       "         0.00585558,  0.20468446,  0.40351335,  0.60234223,  0.80117112,  1.        ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/h+gi4m2Dfr5fQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2288f05b198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "df_poor = pd.read_table('Data/custom_dataset_poor_small.txt', sep='\\t')\n",
    "plt.hist(df_poor.corr().values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 592.,  200.,   60.,   50.,  104.,   72.,   78.,   98.,  194.,  761.]),\n",
       " array([ -9.99997413e-01,  -7.99997671e-01,  -5.99997930e-01,\n",
       "         -3.99998189e-01,  -1.99998448e-01,   1.29361235e-06,\n",
       "          2.00001035e-01,   4.00000776e-01,   6.00000517e-01,\n",
       "          8.00000259e-01,   1.00000000e+00]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD9CAYAAACyYrxEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2288f055748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_rich = pd.read_table('Data/custom_dataset_rich_small.txt', sep = '\\t')\n",
    "plt.hist(df_rich.corr().values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we check the output of the complete datasets, it becomes clear that the simulated datasets are quite perfect datasets. All six datasets have an explained variance perfecentage of 99.99%. The MSE is 0.01 for the datasets with a small amount of noise, 1.0 for the medium datasets and 25 for the data with large amount of noise. The MAE increases from 0.08 to 0.8 to 4.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# table with output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perfect characteristics of these datasets make that the results of certain missing data methods overlap perfect as well (apart from some simulation error). `mean` and `median` imputation give the same results, and `regression` and `stochastic` imputation as well. In addition, the data is that perfect that the loss of records with the `drop.na()` method does not influence the evaluation error metrics. This is the case for all three missingness mechanisms. \n",
    "\n",
    "What we can understand from the simulated datasets, is that the performance of `regression` imputation is clearly affected by the correlation structure of the data. Earlier, we saw that `regression` imputation performs comparable with `mean` and `median` imputation when the correlation structure is poor. For the simulated datasets with the poor correlation structure, `regression` imputation gives even lower MSE, RMSE and MAE values than `mean` and `median` imputation. It seems that `regression` imputation is a useful method when the correlation structure of the data is poor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shot van interactive plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The effect of missing values treatment on the outcome of a data science regression model depends on the characteristics of the data. Yet, we can make some general conclusions. \n",
    "\n",
    "1. The performance of `Regression` imputation is sensitive for the correlation structure in the data\n",
    "2. The percentage of missingness is not "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### de missing data is hetzelfde in de trainingset en testset. de drop methode heeft daarom geen invloed op het verschil in de regressielijn. die wordt in de trainingset net zo getrokken als in de testset. de drop methode geeft daarom een goede predictie mse terug, namelijk dichtbij nul. blijkbaar is het zeer goed te doen om in deze data een regressiepredictie van y te maken op basis van de 50 x-en. dat is op zich ook wel logisch want y is gebaseerd op x. hoe is dat als er meer ruis toegevoegd wordt? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact information\n",
    "\n",
    "Rianne Schouten, Missing Data Specialist, rianne.schouten@dpa.nl\n",
    "\n",
    "Coen Seinen, Data Scientist, coen.seinen@bigdatarepublic.nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
